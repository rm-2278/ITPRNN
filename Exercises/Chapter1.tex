\documentclass[12pt, a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{titlesec}
\usepackage{tcolorbox}
\usepackage{enumitem}
\usepackage[bottom=3cm]{geometry}
\tcbuselibrary{breakable}
\tcbuselibrary{skins}

\newtcolorbox{prob}[1]{colback=gray!5!white, colframe=gray!75!black, 
title=\textbf{Exercise #1}}

\newtcolorbox{sol}{
    breakable,
    colback=white,      % Background matches page
    colframe=white,     % Frame matches page (invisible)
    frame hidden,       % Hides the border line
    left=3mm, right=3mm,% MATCHES the Question box padding
    boxrule=0mm,        % No border width
    top=0mm, bottom=0mm,% Tight vertical spacing
    parbox=false,       % Allows paragraphs to break normally
    before upper={\textbf{Solution:}\par\medskip} % Automatically adds "Solution:" title
}

\begin{document}

\begin{prob}{1.2}
Show that the error probability is reduced by the use of
$R_{3}$ by computing the error probability of this code for a binary symmetric
channel with noise level $f$.
\end{prob}

\begin{sol}
\noindent Without $R_{3}$, we have error probability $f$. \\
With $R_{3}$, we have error probability
\begin{align*}
\binom{3}{2} (1-f)f^2 + f^3 &= 3f^2 - 3f^3 + f^3 = 3f^2 - 2f^3
\end{align*}
Now, 
\begin{align*}
f - (3f^2 - 2f^3) &= f - 3f^2 + 2f^3 \\
                &= f(1-2f)(1-f) > 0  \quad (\because f < \frac{1}{2})
\end{align*}
so $f > 3f^2 - 2f^3$ hence error probability reduced.
\end{sol}
\bigskip

\begin{prob}{1.3}
\begin{enumerate}
    \item[(a)] Show that the probability of error of $\mathrm{R}_N$, the repetition code with $N$ repetitions, is
    \begin{equation}
        p_{\mathrm{b}} = \sum_{n=(N+1)/2}^{N} \binom{N}{n} f^n (1-f)^{N-n}, \tag{1.24}
    \end{equation}
    for odd $N$.
    
    \item[(b)] Assuming $f = 0.1$, which of the terms in this sum is the biggest? How much bigger is it than the second-biggest term?
    
    \item[(c)] Use Stirling's approximation (p.2) to approximate the $\binom{N}{n}$ in the largest term, and find, approximately, the probability of error of the repetition code with $N$ repetitions.
    
    \item[(d)] Assuming $f = 0.1$, find how many repetitions are required to get the probability of error down to $10^{-15}$. [Answer: about 60.]
\end{enumerate}
\end{prob}
\begin{sol}
\begin{enumerate}
\item[(a)]
If $N$ is odd, error when $\frac{N+1}{2}$ or more bits flipped. Hence,

\[
p_b = \sum_{n=(N+1)/2}^{N} \binom{N}{n} f^n (1-f)^{N-n}
\]

\item[(b)]
Let each term $a_n$.
\begin{align*}
\frac{a_{n+1}}{a_n} &= \frac{N! n! (N-n)! f^{n+1} (1-f)^{N-n-1}}{(n+1)! (N-n-1)! N! f^n (1-f)^{N-n}} \\
&= \frac{(N-n)f}{(n+1)(1-f)} = \frac{N-n}{9(n+1)}
\end{align*}
Now,
\begin{align*}
   &\frac{N-n}{9(n+1)} > 1 \\
  \iff & 10n + 9 < n \\
  \iff & n < \frac{N-9}{10} \quad (< \frac{N+1}{2})
\end{align*}
so ratio $< 1$ for all $n \geq \frac{N+1}{2}$, meaning the series is decreasing, hence largest term is when $n = \frac{N+1}{2}$. \\
Ratio is $\frac{N - \frac{N+1}{2}}{9(\frac{N+1}{2} + 1)} = \frac{N - 1}{9N + 11} \simeq \frac{1}{9}$. \\
The largest term is approximately 9 times larger than second-largest term. \\

\item[(c)]
\[
\binom{N}{n} \approx 2^{NH_2(\frac{n}{N})}
\]
Now,
\begin{align*}
  H_2(\frac{\frac{N+1}{2}}{N}) &= \frac{N+1}{2N} \log_2 (\frac{2N}{N+1}) + \frac{N-1}{2N} \log_2 (\frac{2N}{N-1}) \\
  &\simeq \frac{1}{2} \log_2(2) + \frac{1}{2} \log_2(2) = 1
\end{align*}
So,
\begin{align*}
p_b \approx p_B &= \binom{N}{\frac{N+1}{2}} f^{\frac{N+1}{2}} (1-f)^{N - \frac{N+1}{2}}
&\simeq 2^N f^{\frac{N}{2}}(1-f)^{\frac{N}{2}}
&= \{4f(1-f)\}^{\frac{N}{2}}
\end{align*}

\break

\item[(d)]
\begin{align*}
    10^{-15} &= \{4f(1-f)\}^{\frac{N}{2}} \\
    N &= 2 \frac{-15}{\log_{10}4 \cdot 0.1 \cdot 0.9} = 67.91 \approx 68
\end{align*}
or more accrately,
\begin{align*}
    \ln \binom{N}{n} &\simeq (N-n) \log_2 \frac{N}{N-n} + n \log_2 \frac{N}{n} - \frac{1}{2} \log_2(2 \pi \frac{(N-n)n}{N}) \\
    &= NH_2(\frac{n}{N}) - \frac{1}{2} \log(2 \pi \frac{(N-n)n}{N}) \\
    &\xrightarrow{n \simeq \frac{N}{2}} N - \frac{1}{2} \log_2 (\frac{\pi N}{2}) \\[1em]
\binom{N}{n} &\simeq 2 ^ {N - \frac{1}{2} \log_2 (\frac{\pi N}{2})} = \frac{2^N}{\sqrt{\frac{\pi N}{2}}}
\end{align*}
Then, 
\begin{align*}
p_b \approx p_B &\simeq \binom{N}{\frac{N+1}{2}} f^{\frac{N+1}{2}} (1-f)^{\frac{N-1}{2}} \\
&\simeq \frac{2^N}{\sqrt{\frac{\pi N}{2}}} f \{f(1-f)\}^{\frac{N-1}{2}} = \frac{2f}{\sqrt{\frac{\pi N}{2}}} f \{4f(1-f)\}^{\frac{N-1}{2}}
\end{align*}
so
\begin{align*}
10^{-15} &= \frac{0.2}{\sqrt{\frac{\pi N}{2}}} \{4 \cdot 0.1 \cdot 0.9 \}^{\frac{N-1}{2}} \\
\frac{N-1}{2} &= \frac{-15-\log_10 \frac{0.2}{\sqrt{\frac{\pi N}{2}}}}{\log_10 0.36} \\
\end{align*}
Iterate from $\hat{N}_1 = 67.6$
\begin{align*}
    \frac{\hat{N}_2 - 1}{2} &= 29.95 \\
    \hat{N}_2 &= 60.90 \\
    \hat{N}_3 &= 61.00 \\
    \hat{N}_3 &= 61.00
\end{align*}
which results in 61.

\end{enumerate}
\end{sol}
\bigskip


\begin{prob}{1.4}
    Prove that this is so 
    ($\mathbf{Ht} = 
        \begin{bmatrix}
            0 \\ 0 \\ 0
        \end{bmatrix}$) 
    by evaluating the $3 \times 4$ matrix $\mathbf{HG}^{\mathrm{T}}$
\end{prob}
\begin{sol}
    $
    \begin{bmatrix}
        1 & 1 & 1 & 0 & 1 & 0 & 0 \\
        0 & 1 & 1 & 0 & 0 & 1 & 0 \\
        1 & 0 & 1 & 0 & 0 & 0 & 1 
    \end{bmatrix}
        \begin{bmatrix}
        1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 1 \\
        1 & 1 & 1 & 0 \\
        0 & 1 & 1 & 1 \\
        1 & 0 & 1 & 1
    \end{bmatrix}
    = 
    \begin{bmatrix}
        0 \\
        0 \\
        0
    \end{bmatrix}
    $

\end{sol}
\bigskip

\begin{prob}{1.5}
    This exercise and the next three refer to the (7, 4) Hamming code. Decode the received strings:
    \begin{enumerate}
        \item[(a)] r = 1101011
        \item[(b)] r = 0110110
        \item[(c)] r = 0100111
        \item[(d)] r = 1111111
    \end{enumerate}
\end{prob}
\begin{sol} 
    The following are symdrome, unflipped bit and answer.
    \begin{enumerate}
        \item[(a)] $z = 011, r_4, 1100011 $
        \item[(b)] $z = 111, r_3, 0100110$
        \item[(c)] $z = 001, r_7, 0100110$
        \item[(d)] $z = 000, \text{None}, 1111111$
    \end{enumerate}
\end{sol}
\bigskip


\begin{prob}{1.6}
    \begin{enumerate}
        \item[(a)] Calculate the probability of block error $p_B$ of the
(7, 4) Hamming code as a function of the noise level $f$ and show
that to leading order it goes as $21f^2$.
        \item[(b)] Show that to leading order the probability of bit error $p_b$ goes as $9f^2$
    \end{enumerate}
\end{prob}
\begin{sol}
    \begin{enumerate}
    \item[(a)] \begin{align*}
        p_B &= 1 - \sum_{k=0}^{1} \binom{7}{k} f^k (1-f)^{7-k} \\
        &= 1 - (1-f)^7 - 7f(1-f)^6 \\
        &= 1 - (1+6f)(1-f)^6 \\
        &= 1 - (1+6f)(1-6f+15f^2 + O(f^3)) \\
        &= 1 - (1 - 6f + 15f^2 + 6f - 36f^2 + O(f^3)) \\
        &= 21f^2 + O(f^3)
    \end{align*}
    \item[(b)] Let X = the number of bits flipped in a block after decoding.
    \begin{align*}
        E[p_b] &= \frac{1}{7}E[X] \\
        &= \frac{1}{7} \,  (3 \,\binom{7}{2} f^2(1-f)^5 + \sum_{3}^{7} a_k \binom{7}{k} f^k (10f)^{7-k}) \\
        &= \frac{3}{7} \times \frac{7 \cdot 6}{2 \cdot 1} \,f^2 (1-f)^5 + O(f^3) \\
        &= 9f^2(1-f)^5 \\
        &= 9f^2 + O(f^3)
    \end{align*}
    \end{enumerate}
\end{sol}
\bigskip

\begin{prob}{1.7}
Find some noise vectors that give the all-zero syndrome
(that is, noise vectors that leave all the parity checks unviolated). How
many such noise vectors are there?
\end{prob}
\begin{sol}
There are $2^4 = 16$ codewords, so 16 such noise vectors. This is because, by definition, codewords are the only vectors that have the property of $\mathbf{Hn} = 0$. This can be seen from the Venn diagram being uniquely filled if the first 4 bits are determined.
\end{sol}
\bigskip

\begin{prob}{1.8}
I asserted above that a block decoding error will result whenever two or more bits are flipped in a single block. Show that this is
indeed so. [In principle, there might be error patterns that, after decoding, led only to the corruption of the parity bits, with no source bits
incorrectly decoded.]
\end{prob}
\begin{sol}
Assume there is a block error but no decoding error. That is, the source bit is unchanged but the parity bit is changed.
The parity bit is deterministic from the source bit, so if the source bit is the same, the parity bit must also be the same, meaning there would be no block error.
This contradicts with the assumption that the code has a block error, so if there is a block error, there must also be a decoding error.
\end{sol}
\bigskip

\begin{prob}{1.9}
Design an error-correcting code and a decoding algorithm for it, estimate its probability of error, and add it to figure 1.18. [Don’t
worry if you find it difficult to make a code better than the Hamming
code, or if you find it difficult to find a good decoder for your code; that’s
the point of this exercise.]
\end{prob}
\begin{sol}
Similar to how (7, 4) Hamming code was derived, we can draw a 4-circle Venn Diagram to create a (15, 11) code. \\
The generator matrix would be 
\[
\left[
\begin{array}{ccccccccccccccc}
        1 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 \\
        1 & 1 & 0 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 0 \\
        0 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 \\
\end{array}
\right]
\]
This is a code with a distance of 3 (correct one bit).
\end{sol}
\bigskip

\begin{prob}{1.10}
     A (7, 4) Hamming code can correct any one error; might
there be a (14, 8) code that can correct any two errors?
Optional extra: Does the answer to this question depend on whether the
code is linear or nonlinear?
\end{prob}
\begin{sol}
For any code, the space for the received message must be larger than the space for the transmitted message which we are interested in correctly decoding.
Now, the space for which we aim to recover in a two-bit correcting code is, (considering that we must recover the original code (and the noise))
$$
2^8 (\binom{14}{2} + \binom{14}{1} + \binom{14}{0}) = 2^8 (91 + 15 + 1) = 2^8 \cdot 106
$$
The space for the received message is
$$
2^14 = 2^8 \cdot 64 \, < 2^8 \cdot 106
$$
so it is impossible to create a (14, 8) two-bit error correcting code.
This is regardless of whether the code is linear or non-linear.
\end{sol}
\bigskip

\begin{prob}{1.11}
Design an error-correcting code, other than a repetition
code, that can correct any two errors in a block of size N.
\end{prob}
\begin{sol}
Use the bipartite graph to create (30, 11) code which is two-bit error correcting.
\end{sol}
\bigskip

\begin{prob}{1.12}
    Consider the repetition code $R_9$. One way of viewing
this code is as a concatenation of $R_3$ with $R_3$. We first encode the
source stream with $R_3$, then encode the resulting output with $R_3$. We
could call this code ‘$R_3^2$’. This idea motivates an alternative decoding
algorithm, in which we decode the bits three at a time using the decoder
for $R_3$; then decode the decoded bits from that first decoder using the
decoder for $R_3$.
Evaluate the probability of error for this decoder and compare it with
the probability of error for the optimal decoder for $R_9$.
Do the concatenated encoder and decoder for $R_2^3$ have advantages over
those for $R_9$?
\end{prob}
\begin{sol}
Note that the error is introduced at the channel, not the encoder. \\
Considering the dominant term, the error probability for $R_9$ is 
$$p_b(R_9) \simeq \binom{9}{5} f^5 (1-f^4) \simeq 126 f^5 $$
The error probability for an error for each block in $R_3^2$ is
$$
p_B \simeq \binom{3}{2} f^2 (1-f) \simeq 3f^2
$$
and so the error probability for the entire procedure is 
$$
p_b \simeq \binom{3}{2} p_B^2 (1-p_B) \simeq 3 (3f^2)^2 = 27f^4
$$
This means the $R_3^2$ code is suboptimal in it's error correcting. \\
Advantages are that the number of bits that needs to be seen is smaller for each operation, hence cheaper. \\
Also, the hardware can be reused which makes the design simpler.
\end{sol}
\bigskip


% % template
% \begin{prob}{}
% \end{prob}
% \begin{sol}
% \end{sol}
% \bigskip

\end{document}

